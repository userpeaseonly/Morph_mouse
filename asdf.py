import cv2import dlibimport numpy as np# Load the facial landmark detection modelpredictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')# Load the imageimage = cv2.imread('img.png')image_height, image_width = image.shape[:2]# Load the videovideo = cv2.VideoCapture('paste.mp4')# Get video properties (frame rate)fps = video.get(cv2.CAP_PROP_FPS)# Create an output video file with properties from the videoout = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (image_width, image_height))# Define mouth region coordinates for the image (adjust to make the mouth bigger)mouth_region = [(-50, 100), (340, 100), (340, 300), (-50, 300)]# Process frames from the videowhile True:    ret, frame = video.read()    if not ret:        break    # Resize frame to match image dimensions    frame = cv2.resize(frame, (image_width, image_height))    # Convert frame to grayscale for facial landmark detection    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)    # Detect faces and facial landmarks in the frame    detector = dlib.get_frontal_face_detector()    faces = detector(gray)    # If faces are detected    if faces:        shape = predictor(gray, faces[0])        # Extract lip landmarks (assuming landmarks for lips are 48-68)        lip_landmarks = shape.parts()[48:68]        # Enlarge the mouth area in the image        mouth_pts = np.array(mouth_region, np.int32)        # Get the average movement of the lip landmarks in the video frame        lip_movement = np.mean([(l.x, l.y) for l in lip_landmarks], axis=0)        # Update the mouth area in the image using the lip movement        mouth_pts += (lip_movement - np.mean(mouth_pts, axis=0)).astype(np.int32)        # Create a mask for the enlarged mouth area        mask = np.zeros_like(image)        cv2.fillPoly(mask, [mouth_pts], (255, 255, 255))        # Replace the enlarged mouth area in the image with the frame        result = np.where(mask == 255, frame, image)        out.write(result)    else:        out.write(image)  # If no face is detected, use the original image# Release video objects and close outputvideo.release()out.release()cv2.destroyAllWindows()